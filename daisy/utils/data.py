import random
import numpy as np
import pandas as pd
import scipy.sparse as sp
import torch.utils.data as data


class PointData(data.Dataset):
    def __init__(self, neg_set, is_training=True, neg_label_val=0.):
        """
        Dataset formatter adapted point-wise algorithms
        Parameters
        ----------
        neg_set : List, negative sampled result generated by Sampler
        is_training : boolean, whether the procedure using this method is training part
        neg_label_val : float, rating value towards negative sample
        """
        super(PointData, self).__init__()
        self.features_fill = []
        self.labels_fill = []
        for u, i, r, js in neg_set:
            self.features_fill.append([int(u), int(i)])
            self.labels_fill.append(r)
            
            if is_training:
                for j in js:
                    self.features_fill.append([int(u), int(j)])
                    self.labels_fill.append(neg_label_val)
        self.labels_fill = np.array(self.labels_fill, dtype=np.float32)

    def __len__(self):
        return len(self.labels_fill)

    def __getitem__(self, idx):
        features = self.features_fill
        labels = self.labels_fill

        user = features[idx][0]
        item = features[idx][1]
        label = labels[idx]

        return user, item, label


class PairData(data.Dataset):
    def __init__(self, neg_set, is_training=True):
        """
        Dataset formatter adapted pair-wise algorithms
        Parameters
        ----------
        neg_set : List,
        is_training : bool,
        """
        super(PairData, self).__init__()
        self.features_fill = []

        for u, i, r, js in neg_set:
            u, i, r = int(u), int(i), np.float32(1)
            if is_training:
                for j in js:
                    self.features_fill.append([u, i, j, r])
            else:
                self.features_fill.append([u, i, i, r])

    def __len__(self):
        return len(self.features_fill)

    def __getitem__(self, idx):
        features = self.features_fill
        user = features[idx][0]
        item_i = features[idx][1]
        item_j = features[idx][2]
        label = features[idx][3]

        return user, item_i, item_j, label


class UAEData(data.Dataset):
    def __init__(self, user_num, item_num, train_set, test_set):
        """
        user-level Dataset formatter adapted AutoEncoder-like algorithms
        Parameters
        ----------
        user_num : int, the number of users
        item_num : int, the number of items
        train_set : pd.DataFrame, training set
        test_set : pd.DataFrame, test set
        """
        super(UAEData, self).__init__()
        self.user_num = user_num
        self.item_num = item_num

        self.R = sp.dok_matrix((user_num, item_num), dtype=np.float32)  # true label
        self.mask_R = sp.dok_matrix((user_num, item_num), dtype=np.float32) # only concern interaction known
        self.user_idx = np.array(range(user_num))

        for _, row in train_set.iterrows():
            user, item = int(row['user']), int(row['item'])
            self.R[user, item] = 1.
            self.mask_R[user, item] = 1.

        for _, row in test_set.iterrows():
            user, item = int(row['user']), int(row['item'])
            self.R[user, item] = 1.

    def __len__(self):
        return self.user_num

    def __getitem__(self, idx):
        u = self.user_idx[idx]
        ur = self.R[idx].A.squeeze()
        mask_ur = self.mask_R[idx].A.squeeze()

        return u, ur, mask_ur


class IAEData(data.Dataset):
    def __init__(self, user_num, item_num, train_set, test_set):
        """
        item-level Dataset formatter adapted AutoEncoder-like algorithms
        Parameters
        ----------
        user_num : int, the number of users
        item_num : int, the number of items
        train_set : pd.DataFrame, training set
        test_set : pd.DataFrame, test set
        """
        super(IAEData, self).__init__()
        self.user_num = user_num
        self.item_num = item_num
        
        self.R = sp.dok_matrix((item_num, user_num), dtype=np.float32)  # true label
        self.mask_R = sp.dok_matrix((item_num, user_num), dtype=np.float32) # only concern interaction known
        self.item_idx = np.array(range(item_num))

        for _, row in train_set.iterrows():
            user, item = int(row['user']), int(row['item'])
            self.R[item, user] = 1.
            self.mask_R[item, user] = 1.

        for _, row in test_set.iterrows():
            user, item = int(row['user']), int(row['item'])
            self.R[item, user] = 1.

    def __len__(self):
        return self.item_num

    def __getitem__(self, idx):
        i = self.item_idx[idx]
        ir = self.R[idx].A.squeeze()
        mask_ir = self.mask_R[idx].A.squeeze()

        return i, ir, mask_ir
